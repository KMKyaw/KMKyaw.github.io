<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
    <!-- Replace the content tag with appropriate information -->
    <meta name="description" content="DESCRIPTION META TAG" />
    <meta property="og:title" content="SOCIAL MEDIA TITLE TAG" />
    <meta
      property="og:description"
      content="SOCIAL MEDIA DESCRIPTION TAG TAG"
    />
    <meta property="og:url" content="URL OF THE WEBSITE" />
    <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
    <meta property="og:image" content="static/image/your_banner_image.png" />
    <meta property="og:image:width" content="1200" />
    <meta property="og:image:height" content="630" />

    <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG" />
    <meta
      name="twitter:description"
      content="TWITTER BANNER DESCRIPTION META TAG"
    />
    <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
    <meta
      name="twitter:image"
      content="static/images/your_twitter_banner_image.png"
    />
    <meta name="twitter:card" content="summary_large_image" />
    <!-- Keywords for your paper to be indexed by-->
    <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Academic Project Page</title>
    <link rel="icon" type="image/x-icon" href="static/images/favicon.ico" />
    <link
      href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
      rel="stylesheet"
    />

    <link rel="stylesheet" href="static/css/bulma.min.css" />
    <link rel="stylesheet" href="static/css/bulma-carousel.min.css" />
    <link rel="stylesheet" href="static/css/bulma-slider.min.css" />
    <link rel="stylesheet" href="static/css/fontawesome.all.min.css" />
    <link
      rel="stylesheet"
      href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css"
    />
    <link rel="stylesheet" href="static/css/index.css" />

    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
    <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
    <script defer src="static/js/fontawesome.all.min.js"></script>
    <script src="static/js/bulma-carousel.min.js"></script>
    <script src="static/js/bulma-slider.min.js"></script>
    <script src="static/js/index.js"></script>
  </head>
  <body>
    <section class="hero">
      <div class="hero-body">
        <div class="container is-max-desktop">
          <div class="columns is-centered">
            <div class="column has-text-centered">
              <h1 class="title is-2 publication-title">
                A Framework for Synthetic Audio Conversations Generation using
                Large Language Models
              </h1>
              <div class="is-size-5 publication-authors">
                <!-- Paper authors -->
                <span class="author-block">
                  <a href="https://kmkyaw.github.io/" target="#"
                    >Kaung Myat Kyaw</a
                  >,</span
                >
                <span class="author-block">
                  <a href="#" target="_blank"
                    >Jonathan Hoyin Chan</a
                  >,</span
                >
              </div>

              <div class="is-size-5 publication-authors">
                <span class="author-block"
                  >Innovative Cognitive Computing(IC2) Research Center</span
                >
                <br>
                <span class="author-block"
                  >School of Information Technology, </span
                >
                <span class="author-block"
                  >King Mongkut's University of Technology Thonburi</span
                >
              </div>

              <div class="column has-text-centered">
                <div class="publication-links">
                  <!-- Arxiv PDF link -->
                  <span class="link-block">
                    <a
                      href="https://arxiv.org/pdf/2409.00946"
                      target="_blank"
                      class="external-link button is-normal is-rounded is-dark"
                    >
                      <span class="icon">
                        <i class="fas fa-file-pdf"></i>
                      </span>
                      <span>Paper</span>
                    </a>
                  </span>

                  <!-- ArXiv abstract Link -->
                  <span class="link-block">
                    <a
                      href="https://arxiv.org/abs/2409.00946"
                      target="_blank"
                      class="external-link button is-normal is-rounded is-dark"
                    >
                      <span class="icon">
                        <i class="ai ai-arxiv"></i>
                      </span>
                      <span>arXiv</span>
                    </a>
                  </span>
                  
                  <span class="link-block">
                    <a href="#" target="_blank"
                       style="pointer-events: none; opacity: 0.6; cursor: not-allowed;"
                       class="external-link button is-normal is-rounded is-dark"
                       aria-disabled="true">
                      <span class="icon">
                        <i class="fab fa-github"></i>
                      </span>
                      <span>Code</span>
                    </a>
                  </span>
                  
                </div>
              </div>
            </div>
          </div>
        </div>
      </div>
    </section>

    <!-- Paper abstract -->
    <section class="section hero is-light">
      <div class="container is-max-desktop">
        <div class="columns is-centered has-text-centered">
          <div class="column is-four-fifths">
            <h2 class="title is-3">Abstract</h2>
            <div class="content has-text-justified">
              <p>
                In this paper, we introduce ConversaSynth, a framework designed
                to generate synthetic conversation audio using large language
                models (LLMs) with multiple persona settings. The framework
                first creates diverse and coherent text-based dialogues across
                various topics, which are then converted into audio using
                text-to-speech (TTS) systems. Our experiments demonstrate that
                ConversaSynth effectively generates highquality synthetic audio
                datasets, which can significantly enhance the training and
                evaluation of models for audio tagging, audio classification,
                and multi-speaker speech recognition. The results indicate that
                the synthetic datasets generated by ConversaSynth exhibit
                substantial diversity and realism, making them suitable for
                developing robust, adaptable audio-based AI systems.
              </p>
            </div>
          </div>
        </div>
      </div>
    </section>
    <!-- End paper abstract -->

    <section class="section hero is-light">
      <div class="container is-max-desktop">
        <div class="columns is-centered has-text-centered">
          <div class="column is-four-fifths">
            <h2 class="title is-3">Methodology</h2>
            <br>
            <div class="content has-text-justified">
              <div style="text-align: center;">
                <img src="./static/images/methods.png" alt="ConversaSynth Framework" style="width: 30%; height: auto; display: block; margin-left: auto; margin-right: auto;"/>
              </div>
              <br>
              <p>
                Our approach is structured
around key stages, including the selection of a suitable large
language model (LLM), the design of distinct conversational
personas, the process of generating conversations, the conversion of text to speech, and the concatenation of audio dialogues
as displayed in Figure above. Each stage is carefully designed to
ensure the creation of coherent, contextually relevant, and
diverse audio conversations. By leveraging a combination of
advanced models and fine-tuned techniques, we aim to produce
high-quality synthetic dialogues that maintain consistency in
character voices and offer a realistic conversational experience.
The following sections detail the methodologies applied at
each step, from LLM selection to audio post-processing, to
achieve our desired outcomes.
              </p>
            </div>
          </div>
        </div>
      </div>
    </section>
    
    <!-- Youtube video -->
    <section class="hero is-small is-light">
      <div class="hero-body">
        <div class="container">
          <!-- Paper video. -->
          <h2 class="title is-3">Video Presentation</h2>
          <div class="columns is-centered has-text-centered">
            <div class="column is-four-fifths">
              <div class="publication-video">
                <!-- Youtube embed code here -->
                <iframe
                  src="https://www.youtube.com/embed/kgrV3_g9rYY?si=S-VjLUnA4TdvxK8s"
                  frameborder="0"
                  allow="autoplay; encrypted-media"
                  allowfullscreen
                ></iframe>
              </div>
            </div>
          </div>
        </div>
      </div>
    </section>
    <!-- End youtube video -->

    <!-- Paper poster -->
    <section class="hero is-small is-light">
      <div class="hero-body">
        <div class="container">
          <h2 class="title">Poster</h2>

          <img src="static/images/poster.png" alt="Poster" style="width: 100%; max-height: 600px; object-fit: contain;" />
        </iframe>
        </div>
      </div>
    </section>
    <!--End paper poster -->

    <!--BibTex citation -->
    <section class="section" id="BibTeX">
      <div class="container is-max-desktop content">
        <h2 class="title">BibTeX</h2>
        <pre><code>@article{kyaw2024framework,
          title={A Framework for Synthetic Audio Conversations Generation using Large Language Models},
          author={Kyaw, Kaung Myat and Chan, Jonathan Hoyin},
          journal={arXiv preprint arXiv:2409.00946},
          year={2024}
        }</code></pre>
      </div>
    </section>
    <!--End BibTex citation -->

    <footer class="footer">
      <div class="container">
        <div class="columns is-centered">
          <div class="column is-8">
            <div class="content">
              <p>
                This page was built using the
                <a
                  href="https://github.com/eliahuhorwitz/Academic-project-page-template"
                  target="_blank"
                  >Academic Project Page Template</a
                >
                which was adopted from the <a
                  href="https://nerfies.github.io"
                  target="_blank"
                  >Nerfies</a
                > project page.<br />
                This website is licensed under a
                <a
                  rel="license"
                  href="http://creativecommons.org/licenses/by-sa/4.0/"
                  target="_blank"
                  >Creative Commons Attribution-ShareAlike 4.0 International
                  License</a
                >.
              </p>
            </div>
          </div>
        </div>
      </div>
    </footer>

    <!-- Statcounter tracking code -->

    <!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->
  </body>
</html>
